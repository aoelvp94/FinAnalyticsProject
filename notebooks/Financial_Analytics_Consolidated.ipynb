{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Analytics - TP Final\n",
    "## Integrantes: \n",
    "### - *Franco Ferrari*\n",
    "### - *Aldo Escobar*\n",
    "### - *Damian Izanotegui*\n",
    "### - *Nahuel Sanchez*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datasets, computamos las medias móviles, y ploteamos la apariencia inicial del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from pandas_datareader import data as pdr\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numba as nb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, classification_report, roc_auc_score\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from notebooks.mlfinlab.corefns.core_functions import CoreFunctions\n",
    "from notebooks.mlfinlab.corefns.financial_functions import FinancialFunctions\n",
    "\n",
    "# Functions\n",
    "\n",
    "#Cargamos ambos files y los unimos, usando como indices en ambos las fechas.\n",
    "def load_and_join():\n",
    "    mtum = yf.Ticker(\"MTUM\")\n",
    "    stocks = [\"MTUM\"]\n",
    "    start = datetime.datetime(2000,11,30)\n",
    "    end = datetime.datetime(2019,11,30)\n",
    "    \n",
    "    yf.pdr_override()\n",
    "    \n",
    "    df_etf = pdr.get_data_yahoo(stocks, start=start, end=end)\n",
    "    \n",
    "    df = pd.read_excel('https://images.aqr.com/-/media/AQR/Documents/Insights/Data-Sets/Century-of-Factor-Premia-Monthly.xlsx',\n",
    "                      header =18, nrows = 1220)\n",
    "    \n",
    "    df['Date'] =  pd.to_datetime(df['Date'])\n",
    "    \n",
    "    \n",
    "    df = df.set_index('Date')\n",
    "    df = df[['Equity indices Value','Equity indices Momentum','Equity indices Carry','Equity indices Defensive']]\n",
    "    \n",
    "    df_final = df_etf.merge(df, how='left',left_index=True,right_index=True)\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "#Extendemos los datos mensuales a los registros diarios. (Ejemplo: todos los datos de enero, tomaran el valor monthly del 31/01)\n",
    "def fill_joined_missing_fields(df):\n",
    "    for i in range(1,len(df)+1):\n",
    "        if np.isnan(df.iloc[-i,9]):\n",
    "                df.iloc[-i,6] = df.iloc[-i+1,6]\n",
    "                df.iloc[-i,7] = df.iloc[-i+1,7]\n",
    "                df.iloc[-i,8] = df.iloc[-i+1,8]\n",
    "                df.iloc[-i,9] = df.iloc[-i+1,9]\n",
    "         \n",
    "\n",
    "#Introducimos labels al dataset, calculando medias 50 y 200 dias.  \n",
    "def labeling_df(df):\n",
    "    df['50_days_average'] = df.iloc[:,3].rolling(window=10).mean()\n",
    "    df['200_days_average'] = df.iloc[:,3].rolling(window=30).mean()\n",
    "    df.loc[df['50_days_average'] >= df['200_days_average'], 'Buy/Sell'] = -1 #Si la media de corto plazo supera a la de largo, es posicion de sell\n",
    "    df.loc[df['50_days_average'] < df['200_days_average'], 'Buy/Sell'] = 1 #Si la media de corto plazo esta por debajo de la de largo, es posicion de buy\n",
    "    return df\n",
    " \n",
    "#Visualizacion de la evolucion de precios y las medias.\n",
    "def visualize_close_50_200(df):\n",
    "    plt.plot(df['Close'])\n",
    "    plt.plot(df['50_days_average'])\n",
    "    plt.plot(df['200_days_average'])\n",
    "    plt.legend(['Close','50_days_avg','200_days_avg'])\n",
    "    plt.title('Evolution of MTUM ETF over time')\n",
    "    plt.show()\n",
    "    \n",
    "dataset = load_and_join()\n",
    "fill_joined_missing_fields(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy();\n",
    "\n",
    "#Ploteando series\n",
    "df = labeling_df(df);\n",
    "visualize_close_50_200(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< Introducir Notas >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Codigo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< Introducir Notas >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotROC(rf):\n",
    "    y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "    y_pred = rf.predict(X_test)\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    auc = roc_auc_score(y_true = y_test, y_score = y_pred)\n",
    "    print(f\"auc: {auc}\")\n",
    "    \n",
    "plotROC(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferenciacion fraccionaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que el mejor orden de diferenciación es 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consigue los weights para la diferenciacion!\n",
    "def getWeights_FFD(d,size):\n",
    "    w=[1.]\n",
    "    for k in range(1,size):\n",
    "        w_=-w[-1]/k*(d-k+1)\n",
    "        w.append(w_)\n",
    "    w=np.array(w[::-1]).reshape(-1,1)\n",
    "    return w\n",
    "\n",
    "#Funcion aux para pesos de FFD\n",
    "def plotWeights(dRange,nPlots,size):\n",
    "    w=pd.DataFrame()\n",
    "    for d in np.linspace(dRange[0],dRange[1],nPlots):\n",
    "        w_=getWeights_FFD(d,size=size)\n",
    "        w_=pd.DataFrame(w_,index=range(w_.shape[0])[::-1],columns=[d])\n",
    "        w=w.join(w_,how='outer')\n",
    "    ax=w.plot()\n",
    "    ax.legend(loc='upper right');plt.show()\n",
    "    return\n",
    "\n",
    "#Diferenciamos la serie! d es el orden de diferenciacion. \"Thres\" (threshold) maneja la acceptabilidad de las exclusiones. No modificar.\n",
    "#to do\n",
    "def fracDiff(series,d,thres=0.01):\n",
    "\n",
    "    w=getWeights_FFD(d,series.shape[0])\n",
    "\n",
    "    w_=np.cumsum(abs(w))\n",
    "    w_/=w_[-1]\n",
    "    skip=w_[w_>thres].shape[0]\n",
    "\n",
    "    df={}\n",
    "    for name in series.columns:\n",
    "        seriesF,df_=series[[name]].fillna(method='ffill').dropna(),pd.Series()\n",
    "        for iloc in range(skip,seriesF.shape[0]):\n",
    "            loc=seriesF.index[iloc]\n",
    "\n",
    "            df_[loc]=np.dot(w[-(iloc+1):,:].T,seriesF.loc[:loc])[0,0]\n",
    "        df[name]=df_.copy(deep=True)\n",
    "    df=pd.concat(df,axis=1)\n",
    "    return df\n",
    "\n",
    "#Funcion para buscar el mejor d\n",
    "def plotMinFFD(df):\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "    import numpy.ma as ma\n",
    "    out=pd.DataFrame(columns=['adfStat','pVal','lags','nObs','95% conf','corr'])\n",
    "    for d in np.linspace(0,1,21):\n",
    "        df1=np.log(df[['Close']]).resample('1D').last() # Pasar a observaciones diarias\n",
    "        df2=fracDiff(df1,d,thres=.01)\n",
    "        corr = ma.corrcoef(ma.masked_invalid(df1.loc[df2.index,'Close']), ma.masked_invalid(df2['Close']))[0,1]\n",
    "        df2=adfuller(df2['Close'],maxlag=1,regression='c',autolag=None)\n",
    "        out.loc[d]=list(df2[:4])+[df2[4]['5%']]+[corr] # Aportar valores criticos\n",
    "    out[['adfStat','corr']].plot(secondary_y='adfStat')\n",
    "    plt.axhline(out['95% conf'].mean(),linewidth=1,color='r',linestyle='dotted')\n",
    "    plt.show()\n",
    "    return out\n",
    "\n",
    "#Diferenciacion fraccionaria: Buscando el mejor d, d* = 0.1\n",
    "plt.figure(1)\n",
    "out = plotMinFFD(dataset)\n",
    "\n",
    "#Usando la diferenciacion con d = 0.05\n",
    "df_ffd = fracDiff(dataset,0.05)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos pesos por retorno y por tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtiene los factores por retorno para restar importancia a las observaciones.\n",
    "def return_weight(df,price_column):\n",
    "    returns = []\n",
    "    price_array = list(df[price_column])\n",
    "    for i in range(len(price_array)):\n",
    "        if i != (len(price_array)-1):\n",
    "            returns.append(abs(price_array[i+1]-price_array[i]))\n",
    "    weights = []\n",
    "    max_return = max(returns)\n",
    "    for i in range(len(returns)):\n",
    "        weights.append(returns[i]/max_return)\n",
    "    return weights\n",
    "\n",
    "#Obtiene los factores de tiempo para restar importancia a las observaciones.\n",
    "def getTimeDecay(tW,clfLastW=1.):\n",
    "    # apply piecewise-linear decay to observed uniqueness (tW)\n",
    "    # newest observation gets weight=1, oldest observation gets weight=clfLastW\n",
    "    clfW=tW.sort_index().cumsum()\n",
    "    if clfLastW>=0:slope=(1.-clfLastW)/clfW.iloc[-1]\n",
    "    else:slope=1./((clfLastW+1)*clfW.iloc[-1])\n",
    "    const=1.-slope*clfW.iloc[-1]\n",
    "    clfW=const+slope*clfW\n",
    "    clfW[clfW<0]=0\n",
    "    return clfW\n",
    "\n",
    "#Combina multiplicativamente ambos pesos para llegara a ponderadores finales.\n",
    "def final_weight(df,price_column,factor):\n",
    "    return_weights = return_weight(df,price_column)\n",
    "    time_weights = list(getTimeDecay(df[price_column], clfLastW=factor))[:-1]\n",
    "    model_weight = []\n",
    "    for i in range(len(return_weights)):\n",
    "        model_weight.append(return_weights[i]*time_weights[i])\n",
    "    max_w = max(model_weight)\n",
    "    final_weights = []\n",
    "    for i in range(len(model_weight)):\n",
    "        final_weights.append(model_weight[i]/max_w)            \n",
    "    return final_weights\n",
    "\n",
    "model_weights = final_weight(dataset,'close',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< Introducir Notas >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Codigo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< Introducir Notas >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: mejorar graficas, mattplotlib sos muy feo\n",
    "def plotImportance(rf):\n",
    "    # Feature Importance\n",
    "    title = 'Feature Importance:'\n",
    "    figsize = (15, 5)\n",
    "\n",
    "    feat_imp = pd.DataFrame({'Importance':rf.feature_importances_})    \n",
    "    feat_imp['feature'] = X.columns\n",
    "    feat_imp.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "    feat_imp = feat_imp\n",
    "\n",
    "    feat_imp.sort_values(by='Importance', inplace=True)\n",
    "    feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "    feat_imp.plot.barh(title=title, figsize=figsize)\n",
    "    plt.xlabel('Feature Importance Score')\n",
    "    plt.show()\n",
    "    \n",
    "plotImportance(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos:\n",
    "1. Retorno del Portfolio\n",
    "2. Trades Realizados\n",
    "3. Ratio of Longs\n",
    "4. Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_test(df,mode,start_date,end_date, risk_free = 0.0):\n",
    "    df1 = df.loc[start_date:end_date]\n",
    "    ''' Modos disponibles:\n",
    "        1- 'Simple' -> Simple: Toma la performance de una estrategia \"Buy and Hold\". Compra en t=1, vende en t=T (Ultimo dia)\n",
    "        2- 'Signal' -> Señal: Compra y vende segun el campo 'Buy/Sell'. Size es 1 siempre.\n",
    "        3- 'BetS' -> Bet Sizing: Usa la señal del campo Buy/Sell y la pondera por la probabilizada del campo 'BetSize'. '''\n",
    "        \n",
    "    if mode == 'Simple':\n",
    "        print('Modo Simple!')\n",
    "        opening_price = df1['Close'].first('D')[0]\n",
    "        closing_price = df1['Close'].last('D')[0]\n",
    "        result = (closing_price - opening_price) / opening_price\n",
    "        # print('Opening Price: $ {:.2f}'.format(opening_price))\n",
    "        # print('Closing Price: $ {:.2f}'.format(closing_price))\n",
    "        print('Rate of Return: {:.2%}'.format(result))\n",
    "        \n",
    "    elif mode == 'Signal':\n",
    "        print('Modo via señales!')\n",
    "        trades = pd.DataFrame(columns=['Opening_Price','Closing_Price','Return','Type'])\n",
    "        position = 0\n",
    "        for i in range(len(df1)):\n",
    "            if position == 0:\n",
    "                position = df1.iloc[0,12]\n",
    "                open_price = df1.iloc[0,3]\n",
    "            elif position == 1 and (df1.iloc[i,12] == -1 or i == (len(df1)-1)):\n",
    "                # Cambio de Buy a Sell\n",
    "                result = (df1.iloc[i,3] - open_price) / open_price\n",
    "                trades = trades.append({'Opening_Price':open_price,'Closing_Price':df1.iloc[i,3],'Return':result,'Type':'Long'}, ignore_index=True)\n",
    "                open_price = df1.iloc[i,3]\n",
    "                \n",
    "            elif position == -1 and (df1.iloc[i,12] == 1 or i == (len(df1)-1)):\n",
    "                # Cambio de Sell a Buy\n",
    "                result = (open_price - df1.iloc[i,3]) / open_price\n",
    "                trades = trades.append({'Opening_Price':open_price,'Closing_Price':df1.iloc[i,3],'Return':result,'Type':'Short'}, ignore_index=True)\n",
    "                open_price = df1.iloc[i,3]\n",
    "                \n",
    "            position = df1.iloc[i,12]\n",
    "        \n",
    "        # print('*********** Trades ejecutados: **************')\n",
    "        # print('*********************************************')\n",
    "        # for i in range(len(trades)):\n",
    "        #     print('Trade {}, tipo: {}'.format(i,trades.iloc[i,3]))\n",
    "        #     print('Abrio al precio de $ {:.2f} y cerro en $ {:.2f}'.format(trades.iloc[i,0],trades.iloc[i,1]))\n",
    "        #     print('Retorno: {:.2%}'.format(trades.iloc[i,2]))\n",
    "        #     print('*********************************************')\n",
    "        \n",
    "        print('Resultado del Portfolio: {:.2%}'.format(trades['Return'].sum()))\n",
    "        print('Cantidad de trades: 1')\n",
    "                                                 \n",
    "    elif mode == 'BetS':\n",
    "        print('Modo via señales y bet sizing!')\n",
    "        trades = pd.DataFrame(columns=['Opening_Price','Closing_Price','Return','Type','Bet Size'])\n",
    "        position = 0\n",
    "        trade_count = 0\n",
    "        long_count = 0\n",
    "        for i in range(len(df1)):\n",
    "            if position == 0:\n",
    "                position = df1.iloc[0,12]\n",
    "                open_price = df1.iloc[0,3]\n",
    "                bet_size = df1.iloc[0,13]\n",
    "            elif position == 1 and (df1.iloc[i,12] == -1 or i == (len(df1)-1)):\n",
    "                # Cambio de Buy a Sell\n",
    "                result = ((df1.iloc[i,3] - open_price) / open_price)*bet_size\n",
    "                trades = trades.append({'Opening_Price':open_price,'Closing_Price':df1.iloc[i,3],'Return':result,'Type':'Long','Bet Size':bet_size}, ignore_index=True)\n",
    "                open_price = df1.iloc[i,3]\n",
    "                trade_count += 1\n",
    "                long_count += 1\n",
    "                \n",
    "            elif position == -1 and (df1.iloc[i,12] == 1 or i == (len(df1)-1)):\n",
    "                # Cambio de Sell a Buy\n",
    "                result = ((open_price - df1.iloc[i,3]) / open_price)*bet_size\n",
    "                trades = trades.append({'Opening_Price':open_price,'Closing_Price':df1.iloc[i,3],'Return':result,'Type':'Short','Bet Size':bet_size}, ignore_index=True)\n",
    "                open_price = df1.iloc[i,3]\n",
    "                trade_count += 1\n",
    "                \n",
    "                \n",
    "            position = df1.iloc[i,12]\n",
    "            bet_size = df1.iloc[i,13]\n",
    "        \n",
    "        print('*********** Trades ejecutados: **************')\n",
    "        print('*********************************************')\n",
    "        for i in range(len(trades)):\n",
    "            print('Trade {}, tipo: {}'.format(i,trades.iloc[i,3]))\n",
    "            print('Abrio al precio de $ {:.2f} y cerro en $ {:.2f}, con un size de {:.2f}'.format(trades.iloc[i,0],trades.iloc[i,1],trades.iloc[i,4]))\n",
    "            print('Retorno: {:.2%}'.format(trades.iloc[i,2]))\n",
    "            print('*********************************************')\n",
    "        \n",
    "        print('Resultado del Portfolio: {:.2%}'.format(trades['Return'].sum()))\n",
    "        print('Cantidad de trades: {}'.format(trade_count))\n",
    "        print('Ratio of Longs: {:.2%}'.format(long_count/trade_count))\n",
    "        print('Sharpe Ratio: {:.2%}'.format((trades['Return'].sum()-risk_free)/trades['Return'].std()))\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print('Modo incorrecto!')\n",
    "            \n",
    "start_date = '2018-01-02\n",
    "end_date = '2020-01-02'\n",
    "back_test(df,'Simple',start_date,end_date)\n",
    "print('---------------------------------------')\n",
    "# back_test(df,'Signal','2018-01-02','2019-01-02')\n",
    "print('---------------------------------------')\n",
    "back_test(df,'BetS',start_date,end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< Introducir Notas >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Codigo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
